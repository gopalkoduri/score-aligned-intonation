{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get the contour data of each svara\n",
    "* Aggregate contours and plot histogram per raaga/svara (all the artists in the same plot)\n",
    "* Analyze the individual contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import codecs\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import intonation\n",
    "\n",
    "from os import chdir, listdir, mkdir\n",
    "from os.path import isdir, basename, exists\n",
    "from glob import glob\n",
    "\n",
    "%matplotlib tk\n",
    "rcParams['figure.figsize'] = (16.0, 9.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_nearest_index(arr, value):\n",
    "    \"\"\"For a given value, the function finds the nearest value\n",
    "    in the array and returns its index.\"\"\"\n",
    "    arr = array(arr)\n",
    "    index = (abs(arr-value)).argmin()\n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Varnam dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_contours(note_alignment_file, pitch_file):\n",
    "    align_data = json.load(file(note_alignment_file))[basename(note_alignment_file)[13:-5]]\n",
    "    pitch_data = loadtxt(pitch_file)\n",
    "    \n",
    "    contours = {}\n",
    "    \n",
    "    pitch_data[:, 1][isinf(pitch_data[:, 1])] = inf\n",
    "    \n",
    "    for svara in align_data:\n",
    "        start_ind = find_nearest_index(pitch_data[:, 0], svara['interval'][0])\n",
    "        end_ind = find_nearest_index(pitch_data[:, 0], svara['interval'][1])\n",
    "        \n",
    "        if svara['pitchHeight']['Value'] in contours.keys():\n",
    "            contours[svara['pitchHeight']['Value']].append([start_ind, end_ind])\n",
    "        else:\n",
    "            contours[svara['pitchHeight']['Value']] = [[start_ind, end_ind]]\n",
    "    \n",
    "    return contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data_dir = '/homedtic/gkoduri/data/intonation/varnam-analysis/recorded/audio/\n",
    "data_dir = '/home/gkoduri/Dropbox/UPF-Work/PhD/Varnam Analysis/data/audioScoreAlignment/'\n",
    "raagas = ['abhogi', 'begada', 'kalyani', 'mohanam', 'sahana', 'saveri', 'shree']\n",
    "excluded = [i.strip() for i in codecs.open(data_dir + 'exclude.txt').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chdir(data_dir)\n",
    "\n",
    "for raaga in raagas:\n",
    "    print raaga\n",
    "    chdir(raaga)\n",
    "    artists = listdir('.')\n",
    "    artists = [a for a in artists if isdir(a)]\n",
    "    for a in artists:\n",
    "        if raaga + \"/\" + a in excluded:\n",
    "            continue\n",
    "            \n",
    "        chdir(a)\n",
    "        print a,\n",
    "        \n",
    "        alignment_files = glob('alignedNotes*.json')\n",
    "        if 'alignedNotes.json' in alignment_files:\n",
    "            alignment_files.remove('alignedNotes.json')\n",
    "            \n",
    "        for f in alignment_files:\n",
    "            if exists(data_dir+raaga+'/'+a+'/contours_phrase_aligned/'+f[13:-5]+'.pickle'):\n",
    "                continue\n",
    "            try:\n",
    "                contours = get_contours(data_dir+raaga+'/'+a+'/'+f, data_dir+raaga+'/'+a+'/'+a+'-cents.txt')\n",
    "            except (IOError):\n",
    "                print raaga + '/' + a + '/' + f + ' not found!'\n",
    "                continue\n",
    "            if not isdir(data_dir+raaga+'/'+a+'/contours_phrase_aligned/'):\n",
    "                mkdir(data_dir+raaga+'/'+a+'/contours_phrase_aligned/')\n",
    "            pickle.dump(contours, file(data_dir+raaga+'/'+a+'/contours_phrase_aligned/'+f[13:-5]+'.pickle', 'w'))\n",
    "        chdir('..')\n",
    "        \n",
    "    print\n",
    "    chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kriti dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_contours(note_alignment_file, pitch_file):\n",
    "    align_data = json.load(file(note_alignment_file))['dtw_100centBinarization_kmeans']\n",
    "    pitch_data = loadtxt(pitch_file)\n",
    "    \n",
    "    contours = {}\n",
    "    \n",
    "    pitch_data[:, 1][isinf(pitch_data[:, 1])] = inf\n",
    "    \n",
    "    for svara in align_data[0]:\n",
    "        start_ind = find_nearest_index(pitch_data[:, 0], svara['interval'][0])\n",
    "        end_ind = find_nearest_index(pitch_data[:, 0], svara['interval'][1])\n",
    "        \n",
    "        if svara['pitchHeight']['Value'] in contours.keys():\n",
    "            contours[svara['pitchHeight']['Value']].append([start_ind, end_ind])\n",
    "        else:\n",
    "            contours[svara['pitchHeight']['Value']] = [[start_ind, end_ind]]\n",
    "    if '_NaN_' in contours.keys():\n",
    "        contours.pop('_NaN_')\n",
    "    return contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feat_dir = '/homedtic/ssenturk/experiments/20-raagas/features/'\n",
    "contour_dir = '/homedtic/ssenturk/experiments/20-raagas/features/phrase_aligned/'\n",
    "align_dir = '/homedtic/ssenturk/experiments/20-raagas/features/noteAlignments/dtw_100centBinarization_kmeans/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chdir(align_dir)\n",
    "alignment_files = glob('*.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alignment_files[0][:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for f in alignment_files:\n",
    "    if exists('{0}/{1}-contours.pickle'.format(contour_dir, f[:-5])):\n",
    "        continue\n",
    "    try:\n",
    "        contours = get_contours('{0}{1}'.format(align_dir, f), '{0}/pitch/{1}.txt'.format(feat_dir, f[:-5]))\n",
    "    except:\n",
    "        print f, ' is not successful'\n",
    "        continue\n",
    "    pickle.dump(contours, file('{0}/{1}-contours.pickle'.format(contour_dir, f[:-5]), 'w'))\n",
    "    print f, 'is successful'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cents_to_svaras = pickle.load(file('/home/gkoduri/Dropbox/UPF-Work/PhD/Varnam Analysis/data/cents_to_svara_labels.pickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chdir(data_dir)\n",
    "plot_dir = '/home/gkoduri/Dropbox/UPF-Work/PhD/Varnam Analysis/data/plots/phrase_aligned/'\n",
    "\n",
    "for raaga in raagas:\n",
    "    print raaga\n",
    "    chdir(raaga)\n",
    "    artists = listdir('.')\n",
    "    artists = [a for a in artists if isdir(a)]\n",
    "    \n",
    "    svara_data = {}\n",
    "    \n",
    "    # For each artist, for each svara, aggregate all the pitch values corresponding to the contour indices\n",
    "    for a in artists:\n",
    "        try:\n",
    "            contours = pickle.load(file(data_dir+raaga+'/'+a+'/contours_phrase_aligned/dtw_100centBinarization_kmeans.pickle'))\n",
    "            pitch_data = loadtxt(data_dir + raaga + '/' + a + '/' + a + '-cents.txt')\n",
    "            for k, v in contours.items():\n",
    "                pitch_contours = []\n",
    "                for i in v:\n",
    "                    temp = pitch_data[i[0]:i[1], 1]\n",
    "                    temp = [val for val in temp if not isinf(val)]\n",
    "                    pitch_contours.append(temp)\n",
    "                if k in svara_data.keys():\n",
    "                    svara_data[k].append(concatenate(pitch_contours))\n",
    "                else:\n",
    "                    svara_data[k] = [concatenate(pitch_contours)]\n",
    "        except (IOError):\n",
    "            print '{0}/{1} failed!'.format(raaga, a)\n",
    "            continue\n",
    "    \n",
    "    # For each svara, plot histogram of pitch values from each artist seperately\n",
    "    for svara, data in svara_data.items():\n",
    "        if svara < 0 or svara >= 1200:\n",
    "            continue\n",
    "            \n",
    "        figure()\n",
    "        grid(color=\"0.35\")\n",
    "        a_count = 0\n",
    "        for artist_data in data:\n",
    "            n, be = histogram(artist_data, bins=int(max(artist_data)-min(artist_data)), density=True)\n",
    "            bc = (be[1:]+be[:-1])/2.0\n",
    "            ns = gaussian_filter(n, 5)\n",
    "            plot(bc, ns, label=artists[a_count])\n",
    "            a_count += 1\n",
    "            \n",
    "            hold(True)\n",
    "            xlim(svara-350, svara+350)\n",
    "            xticks(fontsize=24)\n",
    "            yticks(fontsize=24)\n",
    "            \n",
    "        xlabel(raaga + ' - ' + str(cents_to_svaras[svara]), fontsize=24)\n",
    "        #legend(fontsize=24)\n",
    "        savefig(plot_dir + raaga + ' - ' + str(cents_to_svaras[svara]).replace('/', '|') + '.pdf', orientation='landscape')\n",
    "        close('all')\n",
    "    \n",
    "    chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
